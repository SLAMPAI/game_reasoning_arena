2025-08-30 13:38:27,708 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:28,023 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:28,214 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:28,426 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:28,685 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:28,914 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:29,268 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:29,435 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:29,612 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:29,825 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:30,148 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:30,453 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:30,678 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:30,857 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:31,141 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:31,396 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:31,573 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:31,801 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:31,975 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:32,158 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:32,408 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:32,622 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:32,845 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:33,023 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:33,235 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:33,472 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:33,678 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:33,894 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:34,159 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:34,393 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:34,584 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:34,786 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:35,031 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:35,221 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:35,420 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:35,662 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:35,900 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:36,110 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:36,294 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:36,469 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:36,732 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:36,920 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:37,111 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:37,367 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:37,588 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:37,817 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:38,050 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:38,269 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:38,791 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:38,966 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:39,193 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:39,440 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:39,627 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:39,916 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:40,231 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:40,533 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:40,714 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:40,889 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:41,055 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:41,263 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:41,466 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:41,660 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:41,854 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:42,044 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:42,264 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:42,460 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:42,624 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:42,808 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:43,010 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:43,299 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:43,562 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:43,780 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:43,996 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:44,161 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:44,427 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:44,595 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:44,804 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:45,022 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:45,248 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:45,464 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:45,683 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:45,925 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:46,155 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:46,344 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:46,531 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:46,732 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:46,954 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:47,186 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:47,808 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:48,015 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:48,235 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:48,471 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:48,835 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:49,029 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:49,191 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:49,373 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:49,534 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:49,745 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:49,941 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:50,182 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:50,361 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:50,539 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:50,738 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:50,911 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:51,131 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:51,307 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:51,483 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:51,684 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:51,856 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:52,037 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:52,255 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:52,453 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:52,663 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:52,878 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:53,099 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:53,309 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:53,519 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:53,702 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:54,050 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:54,351 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:54,551 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:54,735 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:54,926 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:55,116 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
2025-08-30 13:38:55,297 - root - ERROR - Error with model litellm_gpt-5 for player 0: LiteLLM inference failed for gpt-5: OpenAIException - Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}} 
Model: gpt-5
API Base: https://api.openai.com
Messages: [{'role': 'user', 'content': "You are playing the game: hex\nand you are playing with the: x.\n\nthe
