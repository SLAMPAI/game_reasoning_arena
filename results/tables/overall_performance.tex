\begin{table}[htbp]
\centering
\caption{Overall Model Performance Across All Games}
\label{tab:overall_performance}
\begin{tabular}{lcc}
\toprule
Model & Win Rate (\%) & Avg Reward \\
\midrule
\multicolumn{3}{l}{\textbf{OpenAI}}\\
GPT-3.5-turbo & 100.00 & 0.474 ± 0.237 \\
\midrule
\multicolumn{3}{l}{\textbf{Google}}\\
Gemma-7b-it & 100.00 & 0.053 ± 0.026 \\
\midrule
\multicolumn{3}{l}{\textbf{Meta (Llama)}}\\
Meta-Llama-3.1-70B-Instruct-Turbo & 100.00 & 1.000 ± 0.500 \\
llama-3.1-8b-instant & 87.50 & -0.079 ± -0.039 \\
Llama-3-70b-8192 & 87.04 & 0.657 ± 0.328 \\
\midrule
\multicolumn{3}{l}{\textbf{Qwen}}\\
Qwen3-32b & 84.62 & 0.296 ± 0.148 \\
qwen3-235b-a22b-thinking-2507 & 83.33 & 0.287 ± 0.143 \\
\midrule
\multicolumn{3}{l}{\textbf{Meta (Llama)}}\\
Llama-3-8b-8192 & 83.13 & 0.059 ± 0.029 \\
\midrule
\multicolumn{3}{l}{\textbf{Kimi}}\\
kimi-k2-instruct & 81.25 & 0.809 ± 0.405 \\
\midrule
\multicolumn{3}{l}{\textbf{OpenAI}}\\
GPT-4-turbo & 80.00 & 0.789 ± 0.395 \\
\midrule
\multicolumn{3}{l}{\textbf{Meta (Llama)}}\\
Meta-Llama-3.1-8B-Instruct-Turbo & 80.00 & 0.316 ± 0.158 \\
llama-v3-70b-instruct & 80.00 & 0.368 ± 0.184 \\
llama-v3-8b-instruct & 80.00 & 0.368 ± 0.184 \\
\midrule
\multicolumn{3}{l}{\textbf{OpenAI}}\\
GPT-4-mini & 75.00 & 0.201 ± 0.100 \\
\midrule
\multicolumn{3}{l}{\textbf{Other}}\\
o4-mini & 72.73 & 0.292 ± 0.146 \\
\midrule
\multicolumn{3}{l}{\textbf{OpenAI}}\\
GPT-4 & 72.73 & 0.495 ± 0.248 \\
\midrule
\multicolumn{3}{l}{\textbf{Google}}\\
Gemma2-9b-it & 67.24 & 0.270 ± 0.135 \\
\midrule
\multicolumn{3}{l}{\textbf{ZhipuAI}}\\
glm-4p5-air & 64.00 & 0.389 ± 0.195 \\
\midrule
\multicolumn{3}{l}{\textbf{Mistral}}\\
ai-mistralai-Mixtral-8x7B-Instruct-v0.1 & 59.32 & 0.035 ± 0.017 \\
\midrule
\multicolumn{3}{l}{\textbf{Meta (Llama)}}\\
llama-3.1-8b-instant & 0.00 & -0.474 ± -0.237 \\
\midrule
\multicolumn{3}{l}{\textbf{Qwen}}\\
Qwen2-7B-Instruct & 0.00 & -1.000 ± -0.500 \\
\bottomrule
\end{tabular}
\end{table}
